{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be896caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from models.dataset import Dataset\n",
    "from models.ertsrgan.model_generator import g_ertsrgan\n",
    "from models.model_espcn import espcn \n",
    "from models.utils import scale_1 as scale\n",
    "from models.metrics import psnr, ssim, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710d9d0",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf58ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'espcn'\n",
    "#model_name='g_ertsrgan'\n",
    "\n",
    "if model_name == 'g_ertsrgan':\n",
    "    model='g_ertsrgan'\n",
    "if model_name == 'espcn':\n",
    "    model='espcn'\n",
    "    \n",
    "train_dataset_path=\"datasets/train/2x/dataset.tfrecords\"\n",
    "train_dataset_info_path=\"datasets/train/2x/dataset_info.txt\"\n",
    "\n",
    "batch_size=32\n",
    "learning_rate=1e-4\n",
    "num_epochs=10\n",
    "steps_per_epochs=100\n",
    "shuffle_buffer_size=0\n",
    "\n",
    "train_dataset = Dataset(batch_size,\n",
    "        train_dataset_path,\n",
    "        train_dataset_info_path,\n",
    "        shuffle_buffer_size)\n",
    "\n",
    "scale_factor = train_dataset.scale_factor\n",
    "checkpoint_paph=\"{}{}_{}x/model.ckpt\".format(\"checkpoint/\",model_name,scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b565558",
   "metadata": {},
   "outputs": [],
   "source": [
    "if steps_per_epochs == 0:\n",
    "    steps_per_epoch = train_dataset.examples_num // batch_size \\\n",
    "        if train_dataset.examples_num % batch_size != 0 else 0\n",
    "else:\n",
    "    steps_per_epoch = steps_per_epochs\n",
    "\n",
    "train_dataset = train_dataset.get_data(num_epochs)\n",
    "train_batch = train_dataset.map(lambda x0,x1,x2,y: (scale(x1),scale(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94231206",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_paph,\n",
    "        save_weights_only=True,\n",
    "        monitor='loss',\n",
    "        save_freq= 'epoch', \n",
    "        mode='min',\n",
    "        save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8cb0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'g_ertsrgan':\n",
    "    model_2x = g_ertsrgan(scale_factor=scale_factor)\n",
    "if model_name == 'espcn':\n",
    "    model_2x = espcn(scale_factor=scale_factor)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate,clipnorm=1.0)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "model_2x.compile(optimizer=opt, loss=loss,metrics=[psnr,ssim,rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a623b802",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 03:00:02.716826: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-07 03:02:39.157063: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c4c5cb580>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2x.load_weights(checkpoint_paph)\n",
    "\n",
    "for i in range(len(model_2x.layers)):\n",
    "    if(model_2x.layers[i].name != 'final'):\n",
    "        model_2x.layers[i].trainable=True\n",
    "        \n",
    "model_2x.fit(train_batch,epochs=num_epochs,verbose=0,callbacks=checkpoint,steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9139eeed",
   "metadata": {},
   "source": [
    "# ESPCN\n",
    "\n",
    "Without load weights and lr 1e-1 = 7.2917\n",
    "\n",
    "Without load weights and lr 1e-2 = 28.5661\n",
    "\n",
    "Without load weights and lr 1e-3 = 38.8638\n",
    "\n",
    "Without load weights and lr 1e-4 = 27.6628\n",
    "\n",
    "With load weights 1e-3 and lr 1e-4 tranable all layers = 40.3465\n",
    "\n",
    "With load weights 1e-3 and lr 1e-4 tranable only top = 40.1645"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98e140",
   "metadata": {},
   "source": [
    "# g_ertsrgan\n",
    "\n",
    "Without load weights and lr 1e-1 = 5.8966\n",
    "\n",
    "Without load weights and lr 1e-2 = 39.8428\n",
    "\n",
    "Without load weights and lr 1e-3 = 37.7591\n",
    "\n",
    "Without load weights and lr 1e-4 = 31.5835\n",
    "\n",
    "With load weights 1e-2 and lr 1e-3 tranable all layers = 37.6888\n",
    "\n",
    "With load weights 1e-2 and lr 1e-3 tranable only top = 40.5480\n",
    "\n",
    "With load weights 1e-3 and lr 1e-4 tranable all layer = 41.0610 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13124d49",
   "metadata": {},
   "source": [
    "## Model 4x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1adfa6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_2x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83533/2362227216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainable_weights:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"non_trainable_weights:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_trainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_2x' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"weights:\", len(model_2x.weights))\n",
    "print(\"trainable_weights:\", len(model_2x.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(model_2x.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ef96234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'espcn'\n",
    "#model_name='g_ertsrgan'\n",
    "\n",
    "if model_name == 'g_ertsrgan':\n",
    "    model='g_ertsrgan'\n",
    "if model_name == 'espcn':\n",
    "    model='espcn'\n",
    "\n",
    "train_dataset_path=\"../data/reds/train/dataset.tfrecords\"\n",
    "train_dataset_info_path=\"../data/reds/train/dataset_info.txt\"\n",
    "#train_dataset_path=\"datasets/train/4x/dataset.tfrecords\"\n",
    "#train_dataset_info_path=\"datasets/train/4x/dataset_info.txt\"\n",
    "\n",
    "batch_size=32\n",
    "fromScale=2 \n",
    "learning_rate=1e-3\n",
    "num_epochs=100\n",
    "steps_per_epochs=100\n",
    "shuffle_buffer_size=0\n",
    "\n",
    "train_dataset = Dataset(batch_size,\n",
    "        train_dataset_path,\n",
    "        train_dataset_info_path,\n",
    "        shuffle_buffer_size)\n",
    "\n",
    "scale_factor = train_dataset.scale_factor\n",
    "checkpoint_paph=\"{}{}_{}x/model.ckpt\".format(\"checkpoint/\",model_name,scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "817ad6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if steps_per_epochs == 0:\n",
    "    steps_per_epoch = train_dataset.examples_num // batch_size \\\n",
    "        if train_dataset.examples_num % batch_size != 0 else 0\n",
    "else:\n",
    "    steps_per_epoch = steps_per_epochs\n",
    "\n",
    "train_dataset = train_dataset.get_data(num_epochs)\n",
    "train_batch = train_dataset.map(lambda x0,x1,x2,y: (scale(x1),scale(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "545ebbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_paph,\n",
    "        save_weights_only=True,\n",
    "        monitor='loss',\n",
    "        save_freq= 'epoch', \n",
    "        mode='min',\n",
    "        save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbd2d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'g_ertsrgan':\n",
    "    model_4x = g_ertsrgan(scale_factor=scale_factor)\n",
    "if model_name == 'espcn':\n",
    "    model_4x = espcn(scale_factor=scale_factor)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate,clipnorm=1.0)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "model_4x.compile(optimizer=opt, loss=loss,metrics=[psnr,ssim,rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a857875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "espcn\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning\n",
    "\n",
    "checkpoint_paph_2x=\"{}{}_{}x/model.ckpt\".format(\"checkpoint/\",model_name,2)\n",
    "model_2x.load_weights(checkpoint_paph_2x)\n",
    "\n",
    "print(model_2x.name)\n",
    "for i in range(len(model_2x.layers)):\n",
    "    #print(model_2x.layers[i].name)\n",
    "    if(model_2x.layers[i].name != 'final'):\n",
    "        model_4x.layers[i].set_weights(model_2x.layers[i].get_weights())\n",
    "        model_4x.layers[i].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ddac5d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "espcn\n"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "\n",
    "model_4x.load_weights(checkpoint_paph)\n",
    "\n",
    "print(model_4x.name)\n",
    "for i in range(len(model_4x.layers)):\n",
    "    #print(model_4x.layers[i].name)\n",
    "    if(model_4x.layers[i].name != 'final'):\n",
    "        model_4x.layers[i].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec9b76c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 6\n",
      "trainable_weights: 6\n",
      "non_trainable_weights: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"weights:\", len(model_4x.weights))\n",
    "print(\"trainable_weights:\", len(model_4x.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(model_4x.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd72b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 01:38:48.465029: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 30s 292ms/step - loss: 0.0229 - psnr: 19.1489 - ssim: 0.3587 - rmse: 0.1449\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 0.0077 - psnr: 22.5137 - ssim: 0.5359 - rmse: 0.0877\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 0.0070 - psnr: 23.1187 - ssim: 0.5800 - rmse: 0.0838\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0058 - psnr: 24.2481 - ssim: 0.6223 - rmse: 0.0760\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0063 - psnr: 23.6643 - ssim: 0.6053 - rmse: 0.0797\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0061 - psnr: 23.9542 - ssim: 0.6331 - rmse: 0.0779\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.0058 - psnr: 23.9875 - ssim: 0.6228 - rmse: 0.0760\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 0.0057 - psnr: 24.3013 - ssim: 0.6405 - rmse: 0.0755\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0055 - psnr: 24.3748 - ssim: 0.6425 - rmse: 0.0743\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 0.0058 - psnr: 24.1200 - ssim: 0.6393 - rmse: 0.0762\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0057 - psnr: 24.7000 - ssim: 0.6463 - rmse: 0.0754\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0055 - psnr: 24.4152 - ssim: 0.6542 - rmse: 0.0738\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0055 - psnr: 24.5747 - ssim: 0.6525 - rmse: 0.0739\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0054 - psnr: 24.6920 - ssim: 0.6531 - rmse: 0.0736\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 0.0056 - psnr: 24.4248 - ssim: 0.6524 - rmse: 0.0750\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0055 - psnr: 24.2053 - ssim: 0.6390 - rmse: 0.0744\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0048 - psnr: 25.2258 - ssim: 0.6725 - rmse: 0.0692\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 0.0051 - psnr: 24.8433 - ssim: 0.6620 - rmse: 0.0714\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0051 - psnr: 24.8522 - ssim: 0.6564 - rmse: 0.0714\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0051 - psnr: 25.0573 - ssim: 0.6748 - rmse: 0.0717\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0057 - psnr: 24.3162 - ssim: 0.6578 - rmse: 0.0758\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0061 - psnr: 24.1044 - ssim: 0.6347 - rmse: 0.0780\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0057 - psnr: 24.3674 - ssim: 0.6410 - rmse: 0.0754\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.0053 - psnr: 24.7157 - ssim: 0.6607 - rmse: 0.0731\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0052 - psnr: 25.2322 - ssim: 0.6671 - rmse: 0.0724\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0050 - psnr: 25.0336 - ssim: 0.6633 - rmse: 0.0708\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0049 - psnr: 25.0477 - ssim: 0.6701 - rmse: 0.0701\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0055 - psnr: 24.7641 - ssim: 0.6552 - rmse: 0.0743\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0047 - psnr: 25.2463 - ssim: 0.6776 - rmse: 0.0687\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0051 - psnr: 24.8748 - ssim: 0.6618 - rmse: 0.0716\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0053 - psnr: 24.7671 - ssim: 0.6611 - rmse: 0.0726\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0045 - psnr: 25.6728 - ssim: 0.6805 - rmse: 0.0671\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0050 - psnr: 25.1418 - ssim: 0.6676 - rmse: 0.0706\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0050 - psnr: 25.1739 - ssim: 0.6798 - rmse: 0.0709\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0055 - psnr: 24.5560 - ssim: 0.6542 - rmse: 0.0740\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0053 - psnr: 24.5675 - ssim: 0.6528 - rmse: 0.0727\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0044 - psnr: 25.6020 - ssim: 0.6808 - rmse: 0.0664\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0051 - psnr: 25.0984 - ssim: 0.6730 - rmse: 0.0713\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 0.0052 - psnr: 24.8782 - ssim: 0.6636 - rmse: 0.0723\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0047 - psnr: 25.4050 - ssim: 0.6741 - rmse: 0.0686\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0054 - psnr: 24.6358 - ssim: 0.6536 - rmse: 0.0732\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0051 - psnr: 24.6876 - ssim: 0.6509 - rmse: 0.0716\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0057 - psnr: 24.0557 - ssim: 0.6529 - rmse: 0.0756\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0055 - psnr: 24.7293 - ssim: 0.6459 - rmse: 0.0742\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 0.0048 - psnr: 25.2301 - ssim: 0.6854 - rmse: 0.0692\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0048 - psnr: 25.0985 - ssim: 0.6736 - rmse: 0.0696\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0050 - psnr: 25.2253 - ssim: 0.6757 - rmse: 0.0705\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0049 - psnr: 25.2299 - ssim: 0.6767 - rmse: 0.0702\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.0051 - psnr: 25.0702 - ssim: 0.6659 - rmse: 0.0714\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0047 - psnr: 25.2115 - ssim: 0.6742 - rmse: 0.0684\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0047 - psnr: 25.2299 - ssim: 0.6797 - rmse: 0.0689\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 0.0058 - psnr: 24.5856 - ssim: 0.6610 - rmse: 0.0761\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0048 - psnr: 25.1020 - ssim: 0.6765 - rmse: 0.0694\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 0.0050 - psnr: 25.1511 - ssim: 0.6672 - rmse: 0.0708\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0046 - psnr: 25.6372 - ssim: 0.6938 - rmse: 0.0678\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0048 - psnr: 25.4109 - ssim: 0.6732 - rmse: 0.0692\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0050 - psnr: 25.1336 - ssim: 0.6739 - rmse: 0.0706\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0055 - psnr: 24.7058 - ssim: 0.6603 - rmse: 0.0742\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0050 - psnr: 25.2527 - ssim: 0.6774 - rmse: 0.0704\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.0049 - psnr: 25.2052 - ssim: 0.6744 - rmse: 0.0698\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0049 - psnr: 24.9609 - ssim: 0.6606 - rmse: 0.0701\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0051 - psnr: 25.2227 - ssim: 0.6787 - rmse: 0.0713\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0049 - psnr: 25.2573 - ssim: 0.6746 - rmse: 0.0701\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.0052 - psnr: 24.9540 - ssim: 0.6668 - rmse: 0.0719\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0060 - psnr: 24.2125 - ssim: 0.6333 - rmse: 0.0776\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0048 - psnr: 25.4578 - ssim: 0.6718 - rmse: 0.0694\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0050 - psnr: 24.9156 - ssim: 0.6628 - rmse: 0.0709\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0052 - psnr: 24.6244 - ssim: 0.6643 - rmse: 0.0720\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0050 - psnr: 25.0133 - ssim: 0.6735 - rmse: 0.0708\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.0051 - psnr: 25.0483 - ssim: 0.6700 - rmse: 0.0716\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0052 - psnr: 24.7908 - ssim: 0.6695 - rmse: 0.0719\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 0.0053 - psnr: 24.8179 - ssim: 0.6685 - rmse: 0.0726\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 0.0049 - psnr: 24.9422 - ssim: 0.6687 - rmse: 0.0699\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0050 - psnr: 25.2910 - ssim: 0.6731 - rmse: 0.0707\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 0.0054 - psnr: 24.6424 - ssim: 0.6519 - rmse: 0.0735\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 0.0058 - psnr: 24.6132 - ssim: 0.6506 - rmse: 0.0761\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 95s 960ms/step - loss: 0.0045 - psnr: 25.5459 - ssim: 0.6822 - rmse: 0.0674\n",
      "Epoch 78/100\n",
      "  6/100 [>.............................] - ETA: 1:22 - loss: 0.0058 - psnr: 24.7324 - ssim: 0.6750 - rmse: 0.0761"
     ]
    }
   ],
   "source": [
    "model_4x.fit(train_batch,epochs=num_epochs,verbose=1,callbacks=checkpoint,steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cb3181",
   "metadata": {},
   "source": [
    "## ESPCN \n",
    "Without transfer learning: 34.6189\n",
    "\n",
    "With transfer learning, only top tranable, and lr 1e-3: 34.7742\n",
    "\n",
    "With transfer learning, all layers anable, and lr 1e-3:: 34.8456\n",
    "\n",
    "With load weight 1e-3, only top tranable, and lr 1e-4: 36.3229\n",
    "\n",
    "With load weight 1e-3, all layers tranable, and lr 1e-4: 36.6999\n",
    "\n",
    "With load weight 1e-4, all layers tranable, and lr 1e-5: 37.0996\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b2f09",
   "metadata": {},
   "source": [
    "## g_ertsrgan\n",
    "\n",
    "Without transfer learning: 28.3252\n",
    "\n",
    "With transfer learning, only top tranable, and lr 1e-2: 34.1716\n",
    "\n",
    "With transfer learning, all layers tranable, and lr 1e-2: 37.2684\n",
    "\n",
    "With load weight 1e-2, only top tranable, and lr 1e-4: 37.5994  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "ae37652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from collections import OrderedDict\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "shape_lr = (36,36,1)\n",
    "shape_hr = (72,72,1)\n",
    "\n",
    "class VGGLossNoActivation(object):\n",
    "    \"\"\"By ESRGAN a more effective perceptual loss constraining on features before activation rather than \n",
    "    after activation as practiced in SRGAN. \n",
    "    Reference: https://arxiv.org/abs/1809.00219\"\"\"\n",
    "\n",
    "    def __init__(self, image_shape):\n",
    "        self.model = self.create_model(image_shape)\n",
    "        \n",
    "    def create_model(self,image_shape):\n",
    "        \n",
    "        \n",
    "        vgg19 = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_shape=image_shape)\n",
    "\n",
    "        x = tf.keras.layers.Conv2D(512, (3, 3),padding='same',\n",
    "                                   name='block5_conv4')(vgg19.get_layer('block5_conv3').output)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=vgg19.input, outputs=x)\n",
    "        model.trainable = False\n",
    "        return model\n",
    "    \n",
    "    def preprocess_vgg(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            return tf.keras.applications.vgg19.preprocess_input((x))\n",
    "        else:            \n",
    "            return tf.keras.layers.Lambda(lambda x: tf.keras.applications.vgg19.preprocess_input((x)))(x)\n",
    "        \n",
    "    # computes VGG loss \n",
    "    def perceptual_loss(self, y_true, y_pred):\n",
    "        return tf.math.reduce_mean(tf.math.square(self.model(self.preprocess_vgg(y_true)) - self.model(self.preprocess_vgg(y_pred))),None)\n",
    "    \n",
    "    def euclidean_content_loss(self, y_true, y_pred):\n",
    "        return tf.math.sqrt(tf.math.reduce_sum(tf.math.square(self.model(self.preprocess_vgg(y_true)) - self.model(self.preprocess_vgg(y_pred))), axis=None))\n",
    "    \n",
    "    def compoundLoss(self, y_true, y_pred,alfa=10e-2,beta=10e0):\n",
    "        return (alfa * tf.math.reduce_mean(tf.math.square(self.model(self.preprocess_vgg(y_true)) - self.model(self.preprocess_vgg(y_pred))),None) + beta * tf.math.sqrt(tf.math.reduce_sum(tf.math.square(y_pred - y_true), axis=None)))\n",
    "\n",
    "\n",
    "def psnr(y, y_pred,max_val=1.0):\n",
    "    y = tf.image.convert_image_dtype(y, tf.float32)\n",
    "    y_pred = tf.image.convert_image_dtype(y_pred, tf.float32)\n",
    "    values = tf.image.psnr(y, y_pred, max_val=max_val)\n",
    "    return tf.reduce_mean(values)\n",
    "\n",
    "def ssim(y, y_pred,max_val=1.0):\n",
    "    y = tf.image.convert_image_dtype(y, tf.float32)\n",
    "    y_pred = tf.image.convert_image_dtype(y_pred, tf.float32)\n",
    "    values = tf.image.ssim(y, y_pred, max_val=max_val, filter_size=11,\n",
    "                          filter_sigma=1.5, k1=0.01, k2=0.03)\n",
    "    return tf.reduce_mean(values)\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, batch_size, dataset_path, dataset_info_path, shuffle_buffer_size=0):\n",
    "        self._batch_size = batch_size\n",
    "        self._shuffle_buffer_size = shuffle_buffer_size\n",
    "        self._dataset_path = dataset_path\n",
    "        with open(dataset_info_path, 'r') as dataset_info:\n",
    "            self.examples_num = int(dataset_info.readline())\n",
    "            self.scale_factor = int(dataset_info.readline())\n",
    "            self.input_info = OrderedDict()\n",
    "            for line in dataset_info.readlines():\n",
    "                items = line.split(',')\n",
    "                self.input_info[items[0]] = [int(dim) for dim in items[1:]]\n",
    "\n",
    "    def _parse_tf_example(self, example_proto):\n",
    "        features = dict([(key, tf.io.FixedLenFeature([], tf.string)) for key, _ in self.input_info.items()])\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, features=features)\n",
    "\n",
    "        return [tf.reshape(tf.cast(tf.io.decode_raw(parsed_features[key], tf.uint8), tf.float32), value)\n",
    "                for key, value in self.input_info.items()]\n",
    "    \n",
    "    def get_data(self,epoch=None):\n",
    "        dataset = tf.data.TFRecordDataset(self._dataset_path)\n",
    "        dataset = dataset.map(self._parse_tf_example,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.batch(self._batch_size,drop_remainder=True).repeat(epoch)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "def discriminator(filters=64,input_shape=shape_hr):\n",
    "\n",
    "    def conv2d_block(input, filters, strides=1, bn=True):\n",
    "        d = tf.keras.layers.Conv2D(filters, kernel_size=3, strides=strides, padding='same')(input)\n",
    "        if bn:\n",
    "            d = tf.keras.layers.BatchNormalization(momentum=0.8)(d)\n",
    "        d = tf.keras.layers.LeakyReLU(alpha=0.2)(d)\n",
    "        return d\n",
    "    \n",
    "    input = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = conv2d_block(input, filters, bn=False)\n",
    "    x = conv2d_block(x, filters, strides=2)\n",
    "    x = conv2d_block(x, filters*2)\n",
    "    x = conv2d_block(x, filters*2, strides=2)\n",
    "    x = conv2d_block(x, filters*4)\n",
    "    x = conv2d_block(x, filters*4, strides=2)\n",
    "    x = conv2d_block(x, filters*8)\n",
    "    x = conv2d_block(x, filters*8, strides=2)\n",
    "    x = tf.keras.layers.Dense(filters*16)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = tf.keras.layers.Dense(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=input, outputs=x,name='Discriminator')\n",
    "    return model\n",
    "\n",
    "\n",
    "def generator(scale_factor=2):   \n",
    "    inputs = tf.keras.layers.Input(shape=(None,None,1),name='input')\n",
    "    \n",
    "    net = tf.pad(inputs, [[0, 0], [0, 0], [0, 0], [0, 0]], 'SYMMETRIC')\n",
    "    net = tf.keras.layers.Conv2D(32, 3,padding='same',strides=(1, 1), name='conv1',\n",
    "                                kernel_initializer=tf.keras.initializers.HeNormal())(net)\n",
    "    net = tf.keras.layers.LeakyReLU(alpha=0.2)(net)\n",
    "    net1 = net\n",
    "    net = tf.keras.layers.Conv2D(32, 3,padding='same',strides=(1, 1), name='conv2',\n",
    "                                kernel_initializer=tf.keras.initializers.HeNormal())(net)\n",
    "    net = tf.keras.layers.LeakyReLU(alpha=0.2)(net)\n",
    "    net2 = net \n",
    "    net = tf.keras.layers.add([net1, net2])\n",
    "    \n",
    "    net = tf.keras.layers.Conv2D(32, 3,padding='same',strides=(1, 1), name='conv3',\n",
    "                                kernel_initializer=tf.keras.initializers.HeNormal())(net)\n",
    "    net = tf.keras.layers.LeakyReLU(alpha=0.2)(net)\n",
    "    net3 = net\n",
    "    net = tf.keras.layers.concatenate([net1, net2, net3],axis=3)\n",
    "    \n",
    "    net = tf.keras.layers.Conv2D(scale_factor ** 2, 3,activation='tanh', \n",
    "                            padding='same',strides=(1, 1), name='conv4',\n",
    "                            kernel_initializer=tf.keras.initializers.HeNormal())(net)\n",
    "    outputs = tf.keras.layers.Lambda(lambda x:tf.nn.depth_to_space(x,scale_factor),\n",
    "                                        name = 'prediction')(net)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs,name='rtvsrgan')\n",
    "    return model\n",
    "\n",
    "import tensorflow as tf\n",
    "from functools import reduce\n",
    "\n",
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        \n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss, g_loss, metrics):\n",
    "        super(GAN, self).compile(metrics = metrics)\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.d_loss = d_loss \n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.g_loss = g_loss   \n",
    "        \n",
    "    def load_weights_gen(self,checkpoint_filepath):\n",
    "        self.generator.load_weights(checkpoint_filepath)\n",
    "    \n",
    "    def load_weights_dis(self,checkpoint_filepath):\n",
    "        self.discriminator.load_weights(checkpoint_filepath)\n",
    "    \n",
    "    def save_weights_gen(self,checkpoint_filepath):\n",
    "        # Save the weights\n",
    "        self.generator.save_weights(checkpoint_filepath)\n",
    "             \n",
    "        \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            img_lr, img_hr = data\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            img_sr = self.generator(img_lr, training=True)\n",
    "\n",
    "            real_output = self.discriminator(img_hr, training=True)\n",
    "            fake_output = self.discriminator(img_sr, training=True)\n",
    "\n",
    "            g_loss,c_loss, a_loss, p_loss = self.g_loss(fake_output,img_hr,img_sr)\n",
    "            d_loss = self.d_loss(real_output, fake_output)\n",
    "            \n",
    "        gradients_of_generator = gen_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "        self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "        self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "        \n",
    "        self.compiled_metrics.update_state(img_hr, img_sr) \n",
    "        \n",
    "        return reduce(lambda x,y: dict(x, **y), \n",
    "                      ({\"d_loss\": d_loss, \"g_loss\": g_loss,\"a_loss\": a_loss, \"c_loss\": c_loss, \"p_loss\": p_loss },\n",
    "                       {m.name: m.result() for m in self.metrics})) \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "423ef6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from save_img_callback import SaveImageCallback\n",
    "import argparse\n",
    "\n",
    "MODEL='rtvsrgan'\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 4\n",
    "SHUFFLE_BUFFER_SIZE = 45150\n",
    "OPTIMIZER='adam'\n",
    "LEARNING_RATE = 1e-4\n",
    "LEARNING_DECAY_RATE = 1e-1\n",
    "LEARNING_DECAY_EPOCHS = 40\n",
    "MOMENTUM = 0.9\n",
    "NUM_EPOCHS = 100\n",
    "STEPS_PER_EPOCH = 500\n",
    "SAVE_NUM = 2\n",
    "STEPS_PER_LOG = 1000\n",
    "EPOCHS_PER_SAVE = 1\n",
    "LOGDIR = 'logdir'\n",
    "CHECKPOINT = 'checkpoint/'\n",
    "\n",
    "TEST_LOGDIR='test_logdir/'\n",
    "\n",
    "\n",
    "TRAINING_DATASET_PATH='/home/joao/Documentos/projetos/ssd/dataset/train_football-qp17/dataset.tfrecords'\n",
    "TRAINING_DATASET_INFO_PATH='/home/joao/Documentos/projetos/ssd/dataset/train_football-qp17/dataset_info.txt'\n",
    "\n",
    "TESTING_DATASET_PATH='/home/joao/Documentos/projetos/ssd/dataset/test_football-qp17/dataset.tfrecords'\n",
    "TESTING_DATASET_INFO_PATH='/home/joao/Documentos/projetos/ssd/dataset/test_football-qp17/dataset_info.txt'\n",
    "\n",
    "def get_arguments(string=\"\"):\n",
    "    parser = argparse.ArgumentParser(description='train one of the models for image and video super-resolution')\n",
    "    parser.add_argument('--model', type=str, default=MODEL, choices=['espcn','rtvsresnt','rtvsrgan'],\n",
    "                        help='What model to train')\n",
    "    parser.add_argument('--batch_size', type=int, default=BATCH_SIZE,\n",
    "                        help='Number of images in batch')\n",
    "    parser.add_argument('--valid_batch_size', type=int, default=TEST_BATCH_SIZE,\n",
    "                        help='Number of images in test batch')\n",
    "    parser.add_argument('--train_dataset_path', type=str, default=TRAINING_DATASET_PATH,\n",
    "                        help='Path to the train dataset')\n",
    "    parser.add_argument('--train_dataset_info_path', type=str, default=TRAINING_DATASET_INFO_PATH,\n",
    "                        help='Path to the train dataset info')\n",
    "    parser.add_argument('--valid_dataset_path', type=str, default=TESTING_DATASET_PATH,\n",
    "                        help='Path to the test dataset')\n",
    "    parser.add_argument('--valid_dataset_info_path', type=str, default=TESTING_DATASET_INFO_PATH,\n",
    "                        help='Path to the train dataset info')\n",
    "    parser.add_argument('--ckpt_path', default=CHECKPOINT,\n",
    "                        help='Path to the model checkpoint to evaluate')\n",
    "    parser.add_argument('--load_weights', action='store_true',\n",
    "                        help='Path to the model checkpoint to evaluate')\n",
    "    parser.add_argument('--shuffle_buffer_size', type=int, default=SHUFFLE_BUFFER_SIZE,\n",
    "                        help='Buffer size used for shuffling examples in dataset')\n",
    "    parser.add_argument('--optimizer', type=str, default=OPTIMIZER, choices=['adam', 'momentum', 'sgd'],\n",
    "                        help='What optimizer to use for training')\n",
    "    parser.add_argument('--learning_rate', type=float, default=LEARNING_RATE,\n",
    "                        help='Learning rate used for training')\n",
    "    parser.add_argument('--use_lr_decay', action='store_true',\n",
    "                        help='Whether to apply exponential decay to the learning rate')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=LEARNING_DECAY_RATE,\n",
    "                        help='Learning rate decay rate used in exponential decay')\n",
    "    parser.add_argument('--lr_decay_epochs', type=int, default=LEARNING_DECAY_EPOCHS,\n",
    "                        help='Number of epochs before full decay rate tick used in exponential decay')\n",
    "    parser.add_argument('--staircase_lr_decay', action='store_true',\n",
    "                        help='Whether to decay the learning rate at discrete intervals')\n",
    "    parser.add_argument('--num_epochs', type=int, default=NUM_EPOCHS,\n",
    "                        help='Number of training epochs')\n",
    "    parser.add_argument('--steps_per_epochs', type=int, default=STEPS_PER_EPOCH,\n",
    "                        help='How many steps per epochs')\n",
    "    parser.add_argument('--save_num', type=int, default=SAVE_NUM,\n",
    "                        help='How many images to write to summary')\n",
    "    parser.add_argument('--steps_per_log', type=int, default=STEPS_PER_LOG,\n",
    "                        help='How often to save summaries')\n",
    "    parser.add_argument('--epochs_per_save', type=int, default=EPOCHS_PER_SAVE,\n",
    "                        help='How often to save checkpoints')\n",
    "    parser.add_argument('--use_mc', action='store_true',\n",
    "                        help='Whether to use motion compensation in video super resolution model')\n",
    "    parser.add_argument('--mc_independent', action='store_true',\n",
    "                        help='Whether to train motion compensation network independent from super resolution network')\n",
    "    parser.add_argument('--logdir', type=str, default=LOGDIR,\n",
    "                        help='Where to save checkpoints and summaries')\n",
    "    parser.add_argument('--test_logdir', type=str, default=TEST_LOGDIR,\n",
    "                        help='Where to save tests images')\n",
    "\n",
    "    return parser.parse_args(string)\n",
    "\n",
    "\n",
    "args = get_arguments()\n",
    "\n",
    "train_dataset = Dataset(args.batch_size,\n",
    "        args.train_dataset_path,\n",
    "        args.train_dataset_info_path,\n",
    "        args.shuffle_buffer_size)\n",
    "\n",
    "steps_per_epoch = train_dataset.examples_num // args.batch_size \\\n",
    "        if train_dataset.examples_num % args.batch_size != 0 else 0\n",
    "\n",
    "train_dataset = train_dataset.get_data(args.num_epochs)\n",
    "train_batch = train_dataset.map(lambda x0,x1,x2,y: (x1/255.0,y/255.0))\n",
    "\n",
    "\n",
    "valid_dataset = Dataset(args.valid_batch_size,\n",
    "        args.valid_dataset_path,\n",
    "        args.valid_dataset_info_path)\n",
    "\n",
    "valid_dataset = valid_dataset.get_data()\n",
    "    \n",
    "test_batch = valid_dataset.map(lambda x0,x1,x2,y: (x1,y))\n",
    "test_batch = iter(test_batch).get_next() \n",
    "\n",
    "\n",
    "g=generator()\n",
    "d=discriminator()\n",
    "\n",
    "save_img_callback = SaveImageCallback(\n",
    "            dataset=test_batch,\n",
    "            model=g,\n",
    "            model_name=args.model,\n",
    "            epochs_per_save=args.epochs_per_save,\n",
    "            log_dir=args.test_logdir)\n",
    "\n",
    "callbacks=[save_img_callback]\n",
    "\n",
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "adv_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "#cont_loss = tf.keras.losses.MeanAbsoluteError()\n",
    "cont_loss = tf.keras.losses.Huber()\n",
    "#cont_loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "\n",
    "shape_hr = (72,72,3)    \n",
    "vgg_loss = VGGLossNoActivation(shape_hr)\n",
    "perc_loss = vgg_loss.content_loss\n",
    " \n",
    "\n",
    "lbd = 1 * 1e0\n",
    "eta = 1 * 1e0\n",
    "mu = 1 * 1e-2\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    noise = 0.05 * tf.random.uniform(tf.shape(real_output))\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output)-noise, real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output)+noise, fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output,img_hr,img_sr):\n",
    "    noise = 0.05 * tf.random.uniform(tf.shape(fake_output))\n",
    "    a_loss = adv_loss(tf.ones_like(fake_output)-noise, fake_output) * lbd\n",
    "    c_loss = cont_loss(img_hr,img_sr) * eta\n",
    "    img_hr = tf.keras.layers.Concatenate()([img_hr, img_hr, img_hr])\n",
    "    img_sr = tf.keras.layers.Concatenate()([img_sr, img_sr, img_sr])\n",
    "    p_loss = perc_loss(img_hr,img_sr) * mu\n",
    "    total_loss = c_loss + a_loss + p_loss\n",
    "    return total_loss, c_loss , a_loss , p_loss\n",
    "\n",
    "\n",
    "gan = GAN(discriminator = d, generator = g)\n",
    "\n",
    "gan.compile(d_optimizer = tf.keras.optimizers.Adam(learning_rate=args.learning_rate),\n",
    "            g_optimizer = tf.keras.optimizers.Adam(learning_rate=args.learning_rate),\n",
    "            d_loss = discriminator_loss,\n",
    "            g_loss = generator_loss,\n",
    "            metrics=[psnr,ssim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "ac6c7f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 146/1410 [==>...........................] - ETA: 42:00 - d_loss: 1.3863 - g_loss: 0.7057 - a_loss: 0.6931 - c_loss: 0.0124 - p_loss: 2.1462e-04 - psnr: 19.0049 - ssim: 0.3825"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8853/2284985518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-2.6/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.6/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.6/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.6/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.6/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.6/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.6/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.fit(train_batch, epochs=args.num_epochs,verbose=1,steps_per_epoch=steps_per_epoch,callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
